{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(rc={\"figure.figsize\": (20, 10)})\n",
    "plt.rc('figure', figsize=(20, 10))\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pdb\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data_new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action04 = pd.read_csv(data_dir+\"JData_Action_201604.csv\", parse_dates=[\"time\"])\n",
    "action03 = pd.read_csv(data_dir+\"JData_Action_201603.csv\", parse_dates=[\"time\"])\n",
    "action = pd.concat([action04, action03])\n",
    "action_cate8 = action[action.cate==8]\n",
    "action_cate8.to_csv(data_dir+\"train/action0304_cate8.csv\", \n",
    "                                                   index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv(data_dir+\"JData_Product.csv\")\n",
    "users = pd.read_csv(data_dir+\"JData_User.csv\", encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>user_lv_cd</th>\n",
       "      <th>user_reg_tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16746</th>\n",
       "      <td>216747</td>\n",
       "      <td>16-25岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14542</th>\n",
       "      <td>214543</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13850</th>\n",
       "      <td>213851</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12014</th>\n",
       "      <td>212015</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11019</th>\n",
       "      <td>211020</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-06-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10367</th>\n",
       "      <td>210368</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10362</th>\n",
       "      <td>210363</td>\n",
       "      <td>56岁以上</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9394</th>\n",
       "      <td>209395</td>\n",
       "      <td>16-25岁</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8545</th>\n",
       "      <td>208546</td>\n",
       "      <td>16-25岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7482</th>\n",
       "      <td>207483</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7472</th>\n",
       "      <td>207473</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7467</th>\n",
       "      <td>207468</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7463</th>\n",
       "      <td>207464</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>207494</td>\n",
       "      <td>16-25岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7503</th>\n",
       "      <td>207504</td>\n",
       "      <td>16-25岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7457</th>\n",
       "      <td>207458</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>207493</td>\n",
       "      <td>16-25岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7553</th>\n",
       "      <td>207554</td>\n",
       "      <td>16-25岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7510</th>\n",
       "      <td>207511</td>\n",
       "      <td>46-55岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>207513</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>207519</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>207522</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7525</th>\n",
       "      <td>207526</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>207534</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7543</th>\n",
       "      <td>207544</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7544</th>\n",
       "      <td>207545</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7551</th>\n",
       "      <td>207552</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7454</th>\n",
       "      <td>207455</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7452</th>\n",
       "      <td>207453</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7449</th>\n",
       "      <td>207450</td>\n",
       "      <td>16-25岁</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8414</th>\n",
       "      <td>208415</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7776</th>\n",
       "      <td>207777</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7365</th>\n",
       "      <td>207366</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-10-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>207184</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90117</th>\n",
       "      <td>290118</td>\n",
       "      <td>46-55岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89606</th>\n",
       "      <td>289607</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83990</th>\n",
       "      <td>283991</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75830</th>\n",
       "      <td>275831</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73879</th>\n",
       "      <td>273880</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72949</th>\n",
       "      <td>272950</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-07-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67012</th>\n",
       "      <td>267013</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65810</th>\n",
       "      <td>265811</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60711</th>\n",
       "      <td>260712</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2004-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59880</th>\n",
       "      <td>259881</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-04-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59757</th>\n",
       "      <td>259758</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57972</th>\n",
       "      <td>257973</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49723</th>\n",
       "      <td>249724</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42066</th>\n",
       "      <td>242067</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41879</th>\n",
       "      <td>241880</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41750</th>\n",
       "      <td>241751</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40185</th>\n",
       "      <td>240186</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2003-12-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37479</th>\n",
       "      <td>237480</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2003-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36599</th>\n",
       "      <td>236600</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2003-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33083</th>\n",
       "      <td>233084</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2003-11-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26960</th>\n",
       "      <td>226961</td>\n",
       "      <td>26-35岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2003-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16472</th>\n",
       "      <td>216473</td>\n",
       "      <td>16-25岁</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2003-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39240</th>\n",
       "      <td>239241</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2003-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34072</th>\n",
       "      <td>234073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38905</th>\n",
       "      <td>238906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67704</th>\n",
       "      <td>267705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105321 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id     age  sex  user_lv_cd user_reg_tm\n",
       "16746   216747  16-25岁  2.0           1  2016-11-25\n",
       "14542   214543      -1  2.0           1  2016-10-05\n",
       "13850   213851  26-35岁  2.0           3  2016-09-11\n",
       "12014   212015  36-45岁  2.0           2  2016-07-05\n",
       "11019   211020  36-45岁  2.0           3  2016-06-06\n",
       "10367   210368      -1  2.0           1  2016-05-24\n",
       "10362   210363   56岁以上  2.0           2  2016-05-24\n",
       "9394    209395  16-25岁  1.0           2  2016-05-11\n",
       "8545    208546  16-25岁  0.0           2  2016-04-29\n",
       "7482    207483  26-35岁  2.0           3  2016-04-15\n",
       "7472    207473      -1  2.0           1  2016-04-15\n",
       "7467    207468  36-45岁  2.0           3  2016-04-15\n",
       "7463    207464  26-35岁  2.0           2  2016-04-15\n",
       "7493    207494  16-25岁  2.0           3  2016-04-15\n",
       "7503    207504  16-25岁  2.0           4  2016-04-15\n",
       "7457    207458      -1  2.0           1  2016-04-15\n",
       "7492    207493  16-25岁  2.0           3  2016-04-15\n",
       "7553    207554  16-25岁  2.0           4  2016-04-15\n",
       "7510    207511  46-55岁  2.0           5  2016-04-15\n",
       "7512    207513      -1  2.0           1  2016-04-15\n",
       "7518    207519  26-35岁  2.0           2  2016-04-15\n",
       "7521    207522  26-35岁  0.0           3  2016-04-15\n",
       "7525    207526      -1  2.0           3  2016-04-15\n",
       "7533    207534      -1  2.0           1  2016-04-15\n",
       "7543    207544  26-35岁  2.0           3  2016-04-15\n",
       "7544    207545      -1  2.0           1  2016-04-15\n",
       "7551    207552  26-35岁  2.0           3  2016-04-15\n",
       "7454    207455  36-45岁  2.0           3  2016-04-14\n",
       "7452    207453  26-35岁  2.0           3  2016-04-14\n",
       "7449    207450  16-25岁  2.0           3  2016-04-14\n",
       "...        ...     ...  ...         ...         ...\n",
       "8414    208415  36-45岁  0.0           5  2004-10-29\n",
       "7776    207777      -1  0.0           4  2004-10-28\n",
       "7365    207366  36-45岁  0.0           5  2004-10-27\n",
       "7183    207184  36-45岁  0.0           5  2004-10-26\n",
       "90117   290118  46-55岁  0.0           5  2004-09-08\n",
       "89606   289607  36-45岁  0.0           5  2004-09-07\n",
       "83990   283991  26-35岁  0.0           5  2004-08-28\n",
       "75830   275831  26-35岁  0.0           4  2004-07-24\n",
       "73879   273880  36-45岁  0.0           5  2004-07-15\n",
       "72949   272950  36-45岁  0.0           5  2004-07-13\n",
       "67012   267013  36-45岁  0.0           5  2004-06-18\n",
       "65810   265811  36-45岁  0.0           4  2004-06-16\n",
       "60711   260712  26-35岁  0.0           2  2004-05-07\n",
       "59880   259881  36-45岁  0.0           5  2004-04-29\n",
       "59757   259758  26-35岁  0.0           5  2004-04-27\n",
       "57972   257973  36-45岁  0.0           5  2004-04-16\n",
       "49723   249724  26-35岁  0.0           5  2004-03-15\n",
       "42066   242067      -1  0.0           5  2004-01-13\n",
       "41879   241880  36-45岁  0.0           5  2004-01-10\n",
       "41750   241751  36-45岁  0.0           5  2004-01-09\n",
       "40185   240186      -1  0.0           5  2003-12-21\n",
       "37479   237480  36-45岁  0.0           5  2003-12-08\n",
       "36599   236600      -1  1.0           5  2003-12-02\n",
       "33083   233084  26-35岁  0.0           5  2003-11-11\n",
       "26960   226961  26-35岁  0.0           5  2003-10-15\n",
       "16472   216473  16-25岁  0.0           4  2003-09-05\n",
       "39240   239241  36-45岁  1.0           5  2003-06-16\n",
       "34072   234073     NaN  NaN           1         NaN\n",
       "38905   238906     NaN  NaN           1         NaN\n",
       "67704   267705     NaN  NaN           1         NaN\n",
       "\n",
       "[105321 rows x 5 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.sort_values('user_reg_tm', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_age(age_str):\n",
    "    if age_str == u'-1':\n",
    "        return 0\n",
    "    elif age_str == u'15岁以下':\n",
    "        return 1\n",
    "    elif age_str == u'16-25岁':\n",
    "        return 2\n",
    "    elif age_str == u'26-35岁':\n",
    "        return 3\n",
    "    elif age_str == u'36-45岁':\n",
    "        return 4\n",
    "    elif age_str == u'46-55岁':\n",
    "        return 5\n",
    "    elif age_str == u'56岁以上':\n",
    "        return 6\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def get_basic_user_feat():\n",
    "    dump_path = data_dir+'basic_user.pkl'\n",
    "    if os.path.exists(dump_path):\n",
    "        user = pickle.load(open(dump_path))\n",
    "    else:\n",
    "        user = pd.read_csv(data_dir+\"JData_User.csv\", encoding='gbk')\n",
    "        user['age'] = user['age'].map(convert_age)\n",
    "        age_df = pd.get_dummies(user[\"age\"], prefix=\"age\")\n",
    "        sex_df = pd.get_dummies(user[\"sex\"], prefix=\"sex\")\n",
    "        user_lv_df = pd.get_dummies(user[\"user_lv_cd\"], prefix=\"user_lv_cd\")\n",
    "        user = pd.concat([user['user_id'], age_df, sex_df, user_lv_df], axis=1)\n",
    "        pickle.dump(user, open(dump_path, 'w'))\n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_basic = get_basic_user_feat()\n",
    "user_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_cate8 = pd.read_csv(data_dir+\"train/action0304_cate8.csv\", parse_dates=[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action_type = pd.read_csv(data_dir+'train/action_type.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action_type_rich = pd.read_csv(data_dir+'train/action_type_rich.csv', parse_dates=['date'])\n",
    "action_type_rich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有效用户--有加购或关注行为的用户"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_users = pd.DataFrame(action_type_rich[(action_type_rich.action_type_2 > 0)|(action_type_rich.action_type_5>0)].user_id.unique(), columns=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action_type_valid = pd.merge(action_type_rich, valid_users, on='user_id')\n",
    "action_type_valid.to_csv(data_dir+'train/action_type_valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action_type_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 每种商品每天有多少人有过交互"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (sku_id, date), g in action_type.groupby(['sku_id', 'date'], as_index=False).apply(len).iteritems():\n",
    "    print sku_id, date, g\n",
    "    if random.random() > 0.9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.merge(action_type, pd.DataFrame(action_type.groupby(['sku_id', 'date'], as_index=False).apply(len)), \n",
    "         left_on=['sku_id', 'date'], right_index=True)\n",
    "result = pd.merge(result, pd.DataFrame(action_type.groupby('date').apply(len)),\n",
    "        left_on=['date'], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.rename(index=str, columns={'0_x':'user_count_for_sku', '0_y':'active_users'}).to_csv(\"action_type_rich.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# target_dates = [['20160311', '20160315'], \n",
    "#                     ['20160326', '20160331'], \n",
    "#                     ['20160411', '20160416']]\n",
    "target_dates = pd.date_range('20160311', '20160411', freq='D')\n",
    "target_dates = [[t.strftime(\"%Y%m%d\"), (t+datetime.timedelta(days=1)).strftime(\"%Y%m%d\")] for t in target_dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_dfs = []\n",
    "for target_date in target_dates:\n",
    "    buy_action = action_type_valid[(action_type_valid.action_type_4>0)&\\\n",
    "                              (action_type_valid.date >= target_date[0])&(action_type_valid.date < target_date[1])]\n",
    "    window_start = (datetime.datetime.strptime(target_date[0], '%Y%m%d') - datetime.timedelta(days=10)).strftime(\"%Y%m%d\")\n",
    "    window_end = target_date[0]\n",
    "    window_action = action_type_valid[(action_type_valid.date >= window_start)&(action_type_valid.date < window_end)]\n",
    "    pos = pd.merge(buy_action[['user_id', 'sku_id', 'date']], window_action, on='user_id', how='inner')\n",
    "    pos['window_start'] = window_start\n",
    "    pos['window_end'] = window_end\n",
    "    pos_dfs.append(pos)\n",
    "\n",
    "all_pos = pd.concat(pos_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_valid(all_pos, 'positive_valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_pos\\\n",
    ".to_csv(data_dir+\"train/positive.csv\",\n",
    "                                index=False, encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_valid(df, fname):\n",
    "    sum_by_date = df.groupby(['user_id', 'date_x'], as_index=False).sum()\n",
    "    valid = sum_by_date[(sum_by_date.action_type_2>0)|(sum_by_date.action_type_5>0)] \n",
    "    print len(valid)\n",
    "    df['date_x'] = df['date_x'].map(pd.to_datetime)\n",
    "    merged = pd.merge(df, valid[['user_id', 'date_x']], on = ['user_id', 'date_x'])\n",
    "    print len(merged)\n",
    "    merged.to_csv(data_dir+\"train/\"+fname+\".csv\",\n",
    "                                index=False, encoding='gbk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_dfs = []\n",
    "cv_neg_dfs = []\n",
    "for target_date in target_dates:\n",
    "    buy_action = action_type_valid[(action_type_valid.action_type_4>0)&\\\n",
    "                              (action_type_valid.date == target_date[0])]\n",
    "    buyer_id = buy_action.user_id.unique()\n",
    "    all_user_id = action_type_valid[(action_type_valid.date >= target_date[0])&(action_type_valid.date<target_date[1])].user_id.unique()\n",
    "    cv_neg_id, not_buyer_id = train_test_split(list(set(all_user_id) - set(buyer_id)), test_size=0.02)\n",
    "    date = datetime.datetime.strptime(target_date[0], \"%Y%m%d\") + datetime.timedelta(hours=10)\n",
    "    window_start = (datetime.datetime.strptime(target_date[0], '%Y%m%d') - datetime.timedelta(days=10)).strftime(\"%Y%m%d\")\n",
    "    window_end = target_date[0]\n",
    "    arr = [[user_id, 0, date, window_start, window_end] for user_id in not_buyer_id]\n",
    "    cv_neg_arr = [[user_id, 0, date, window_start, window_end] for user_id in cv_neg_id]\n",
    "#     not_buyer_action = pd.DataFrame(np.array(not_buyer_id), columns=['user_id'])\n",
    "    not_buyer_action = pd.DataFrame(np.array(arr), \n",
    "            columns=['user_id','sku_id','date','window_start','window_end'])\n",
    "    \n",
    "    window_action = action_type_valid[(action_type_valid.date >= window_start)&(action_type_valid.date < window_end)]\n",
    "    neg = pd.merge(not_buyer_action, window_action, on='user_id', how='inner')\n",
    "    neg_dfs.append(neg)\n",
    "    \n",
    "    if target_date[0] > '20160410':\n",
    "        cv_neg_action = pd.DataFrame(np.array(cv_neg_arr), \n",
    "                columns=['user_id','sku_id','date','window_start','window_end'])\n",
    "        cv_neg = pd.merge(cv_neg_action, window_action, on='user_id', how='inner')\n",
    "        cv_neg_dfs.append(cv_neg)\n",
    "    \n",
    "all_cv_neg = pd.concat(cv_neg_dfs)\n",
    "all_neg = pd.concat(neg_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_valid(all_neg, 'negative_valid')\n",
    "create_valid(all_cv_neg, 'cv_negative_valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_neg.to_csv(data_dir+\"train/negative.csv\",\n",
    "                                index=False, encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cv_neg.to_csv(data_dir+\"train/cv_negative.csv\",\n",
    "                                index=False, encoding='gbk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "test_df = pd.DataFrame(action_type_valid[action_type_valid.date >= '20160406'].user_id.unique(), \n",
    "                       columns=['user_id'])\n",
    "test_df['date'] = datetime.datetime(2016, 4, 16)\n",
    "test_df['sku_id'] = 0\n",
    "test_df['window_start'] = '20160406'\n",
    "test_df['window_end'] = '20160416'\n",
    "\n",
    "test_df = pd.merge(test_df, action_type_valid[action_type_valid.date >= '20160406'], on = 'user_id')\n",
    "create_valid(test_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type_count = {}\n",
    "for (sid, t), g in action_cate8.groupby(['sku_id', 'type']):\n",
    "    type_count[(sid, t)] = len(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items = np.hstack((np.array([0]), action_cate8.sku_id.unique()))\n",
    "\n",
    "users = action_cate8.user_id.unique()\n",
    "\n",
    "userid2idx = {o:i for i,o in enumerate(users)}\n",
    "itemid2idx = {o:i for i,o in enumerate(items)}\n",
    "\n",
    "n_users = len(users)\n",
    "n_items = len(items)\n",
    "n_factors = 50\n",
    "n_users, n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_2dcnn_dataset(df):\n",
    "    dual_group = df.groupby(['user_id', 'sku_id_x', 'window_start'])\n",
    "    feature = []\n",
    "    label = []\n",
    "    for (uid, sid_buy, window_start), g in dual_group:\n",
    "#         print time_buy\n",
    "        window = []\n",
    "        date_range = pd.date_range(start=str(window_start), periods=10, freq='D',closed='left')\n",
    "#         print date_range\n",
    "#         pdb.set_trace()\n",
    "        for d in date_range:\n",
    "            day_top10 = []\n",
    "            day = d.strftime(\"%Y%m%d\")\n",
    "#             pdb.set_trace()\n",
    "            # 取一天之中action最多的商品\n",
    "            sku_day = g[g.time_y.dt.strftime(\"%Y%m%d\") == day]\n",
    "            sku_action_count = sku_day.sku_id_y.value_counts()\n",
    "            \n",
    "            if len(sku_action_count) == 0:\n",
    "                max_sku_ids = []\n",
    "            else:\n",
    "                max_sku_ids = sku_action_count.index[np.argsort(sku_action_count)[::-1].values[:10]]\n",
    "                \n",
    "            for i in range(10):\n",
    "                try:\n",
    "                    max_sku_id = max_sku_ids[i]\n",
    "                    max_sku_type = sku_day[sku_day.sku_id_y==max_sku_id]['type_y'].value_counts()\n",
    "                except:\n",
    "                    max_sku_id = 0\n",
    "                    max_sku_type = {j:0 for j in range(1,7)}\n",
    "\n",
    "                c_arr = [0] * 12\n",
    "                for t, c in max_sku_type.iteritems():\n",
    "                    t = int(t)\n",
    "                    c_arr[t-1] = c\n",
    "                    c_arr[t-1+6] = type_count.get((max_sku_id, t), 0)\n",
    "\n",
    "                day_top10.append([userid2idx[uid], itemid2idx[max_sku_id]] + c_arr)\n",
    "                \n",
    "            window.append(day_top10)\n",
    "        feature.append(window)\n",
    "        label.append([itemid2idx[sid_buy], 0 if sid_buy == 0 else 1])\n",
    "    return np.array(feature), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "test_df = pd.DataFrame(action_cate8[action_cate8.time > '20160406'].user_id.unique(), \n",
    "                       columns=['user_id']).sample(10)\n",
    "test_df['time'] = datetime.datetime(2016, 4, 16)\n",
    "test_df['sku_id'] = 0\n",
    "test_df['window_start'] = '20160406'\n",
    "test_df['window_end'] = '20160416'\n",
    "test_df = pd.merge(test_df, action_cate8[action_cate8.time > '20160406'], on = 'user_id')\n",
    "\n",
    "test, _ = create_2dcnn_dataset(test_df.rename(index=str, columns={\"type\": \"type_y\"}))\n",
    "\n",
    "utils.save_array('data_new/'+'sample/test_cnn2d', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = utils.load_array('data_new/test_cnn2d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for t in range(2,8):\n",
    "    plt.figure()\n",
    "    sns.heatmap(np.sum(test[:, :, :, t], 0)\\\n",
    "                       /float(len(test)), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_buy = action_cate8[action_cate8.type==4]['sku_id'].unique()\n",
    "set_positive = all_pos.sku_id_x.unique()\n",
    "set(set_buy) - set(set_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action_cate8[(action_cate8.sku_id==26796)&(action_cate8.type==4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "action_cate8[(action_cate8.user_id==13636)].sort_values('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = all_pos[all_pos.time_x < '20160411']\n",
    "cv = all_pos[all_pos.time_x > '20160411']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items = action_cate8.sku_id.unique()\n",
    "\n",
    "users = action_cate8.user_id.unique()\n",
    "\n",
    "userid2idx = {o:i for i,o in enumerate(users)}\n",
    "itemid2idx = {o:i for i,o in enumerate(items)}\n",
    "\n",
    "n_factors = 50\n",
    "n_users = len(users)\n",
    "n_items = len(items)\n",
    "n_users, n_items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_user = len(all_pos.groupby(['user_id', 'sku_id_x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type_count = {}\n",
    "for (sid, t), g in action_cate8.groupby(['sku_id', 'type']):\n",
    "    type_count[(sid, t)] = len(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(df):\n",
    "    tri_group = df.groupby(['user_id', 'sku_id_x'])\n",
    "    trn = []\n",
    "    trn_label = []\n",
    "    for (uid, sid_buy), g in tri_group:\n",
    "        for oth_sid, og in g.groupby('sku_id_y'):\n",
    "            c_arr = [0] * 12\n",
    "            for t, c in g.type_y.value_counts().iteritems():\n",
    "                c_arr[t-1] = c\n",
    "                c_arr[t-1+6] = type_count[(oth_sid, t)]\n",
    "            trn.append([userid2idx[uid], itemid2idx[sid_oth]] + c_arr)\n",
    "            trn_label.append(itemid2idx[sid_buy])\n",
    "    return np.array(trn), np.array(trn_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Negtive Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_user = list(set(action_cate8.user_id) - set(all_pos.user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg_arr = []\n",
    "ratio = (1 - pos_user / float(neg_user) / 30)\n",
    "print ratio\n",
    "for d in pd.date_range(start='20160315', end='20160416', freq='D'):\n",
    "    nu = neg_user[np.random.rand(len(neg_user))>ratio]\n",
    "    for u in nu:\n",
    "        neg_arr.append([u, 0, d])\n",
    "\n",
    "neg_df = pd.DataFrame(np.array(neg_arr), columns=['user_id', 'sku_id', 'time'])\n",
    "neg = pd.merge(neg_df, action_cate8, on='user_id', how='left')\n",
    "#     action_cate8[(action_cate8.user_id.isin(neg_user))\\\n",
    "#                  &(action_cate8.time.between(window_start, window_end))].to_csv(\"data/train/negtive.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "neg_dfs = []\n",
    "ratio = (1 - pos_user / float(len(neg_user)) / 30)\n",
    "neg_df = None\n",
    "for d in pd.date_range(start='20160315', end='20160416', freq='D'):\n",
    "    window_start = d - datetime.timedelta(days=10)\n",
    "    window_end = d \n",
    "    neg_user_sample = np.array(neg_user)[np.random.rand(len(neg_user))>ratio]\n",
    "    window_data = action_cate8[action_cate8.time.between(window_start, window_end)\\\n",
    "                    &(action_cate8.user_id.isin(neg_user))]\n",
    "    neg_users_inside_window = window_data.user_id.unique()\n",
    "    neg_users_sample = neg_users_inside_window[np.random.rand(len(neg_users_inside_window))>ratio]\n",
    "    neg_data = window_data[window_data.user_id.isin(neg_users_sample)]\n",
    "    neg_data['time_x'] = d\n",
    "    neg_data['sku_id_x'] = 0\n",
    "\n",
    "    neg_dfs.append(neg_data)\n",
    "    \n",
    "neg_dfs\n",
    "#     action_cate8[(action_cate8.user_id.isin(neg_user))\\\n",
    "#                  &(action_cate8.time.between(window_start, window_end))].to_csv(\"data/train/negtive.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_df = pd.concat(neg_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_df.to_csv(\"data/train/negtive.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(neg.groupby(['user_id', 'sku_id_x', 'sku_id_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg['window_end'] = neg.apply(lambda x: \\\n",
    "            datetime.datetime.strptime(x.time_x.strftime(\"%Y%m%d\"), \"%Y%m%d\"), 1)\n",
    "neg['window_start'] = neg.apply(lambda x: \\\n",
    "            datetime.datetime.strptime((x.time_x - datetime.timedelta(days=10)).strftime(\"%Y%m%d\"), \"%Y%m%d\"), 1)\n",
    "\n",
    "neg[neg.time_y.between(neg.window_start, neg.window_end)]\\\n",
    "    [['user_id', 'sku_id_x', 'sku_id_y', 'time_x', 'time_y', 'model_id', 'type', 'cate', 'brand']]\\\n",
    "                        .to_csv(\"data/train/negtive.csv\",\n",
    "                                index=False, encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.argmax(neg.sku_id_y.value_counts())\n",
    "len(neg[neg.sku_id_y==12564])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items = np.hstack((np.array([0]), action_cate8.sku_id.unique()))\n",
    "\n",
    "users = action_cate8.user_id.unique()\n",
    "\n",
    "userid2idx = {o:i for i,o in enumerate(users)}\n",
    "itemid2idx = {o:i for i,o in enumerate(items)}\n",
    "\n",
    "n_users = len(users)\n",
    "n_items = len(items)\n",
    "n_factors = 50\n",
    "n_users, n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targets = np.hstack((all_pos['sku_id_x'].unique(), np.array([0])))\n",
    "targetid2idx = {o:i for i,o in enumerate(targets)}\n",
    "n_targets = len(targets)\n",
    "n_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "def create_cnn_dataset(df):\n",
    "    dual_group = df.groupby(['user_id', 'sku_id_x', 'time_x'])\n",
    "    feature = []\n",
    "    label = []\n",
    "    for (uid, sid_buy, time_buy), g in dual_group:\n",
    "#         print time_buy\n",
    "        window = []\n",
    "        date_range = pd.date_range(end=time_buy.strftime(\"%Y%m%d\"),\n",
    "                                   periods=11, freq='D', closed='left')\n",
    "#         print date_range\n",
    "        for d in date_range:\n",
    "            day_top10 = []\n",
    "            day = d.strftime(\"%Y%m%d\")\n",
    "#             print day\n",
    "            # 取一天之中action最多的商品\n",
    "            sku_day = g[g.time_y.dt.strftime(\"%Y%m%d\") == day]\n",
    "            sku_action_count = sku_day.sku_id_y.value_counts()\n",
    "            if len(sku_action_count) == 0:\n",
    "                max_sku_ids = []\n",
    "            else:\n",
    "                max_sku_ids = np.argsort(sku_action_count)[:10]\n",
    "                \n",
    "            for i in range(10):\n",
    "                try:\n",
    "                    max_sku_id = max_sku_ids.index[i]\n",
    "                    max_sku_type = sku_day[sku_day.sku_id_y==max_sku_id]['type_y'].value_counts()\n",
    "                except:\n",
    "                    max_sku_id = 0\n",
    "                    max_sku_type = {j:0 for j in range(1,7)}\n",
    "\n",
    "                c_arr = [0] * 12\n",
    "                for t, c in max_sku_type.iteritems():\n",
    "                    c_arr[t-1] = c\n",
    "                    c_arr[t-1+6] = type_count.get((max_sku_id, t), 0)\n",
    "                \n",
    "                day_top10.append([userid2idx[uid], itemid2idx[max_sku_id]] + c_arr)\n",
    "                \n",
    "            window.append(day_top10)\n",
    "        feature.append(window)\n",
    "        label.append([targetid2idx[sid_buy], 0 if sid_buy == 0 else 1])\n",
    "    return np.array(feature), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample, label_sample = create_cnn_dataset(pos04.head(100))\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "test_df = pd.DataFrame(action_cate8[action_cate8.time > '20160406'].user_id.unique(), \n",
    "                       columns=['user_id'])\n",
    "test_df['time'] = datetime.datetime(2016, 4, 16)\n",
    "test_df['sku_id'] = 0\n",
    "test_df = pd.merge(test_df, action_cate8[action_cate8.time > '20160406'], on = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test2d, _ = create_cnn_dataset(test_df.rename(index=str, columns={\"type\": \"type_y\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "c=bcolz.carray(test, rootdir='test', mode='w')\n",
    "c.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(rc={\"figure.figsize\": (20, 10)})\n",
    "plt.rc('figure', figsize=(20, 10))\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pandas import Timedelta\n",
    "sns.factorplot(x='time', kind='count', data=action_cate8[action_cate8.type==4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.zeros(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
